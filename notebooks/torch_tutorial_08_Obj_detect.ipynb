{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"torch_tutorial_08_Obj_detect.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit"},"language_info":{"name":"python","version":"3.9.5"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"eba825fa16f94cc6a7049f0c12f28b59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8151a09c160747c3a779c0f0ee38e417","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed450902b9d64b479cc55d2ee940ae68","IPY_MODEL_aba9df5eae754d889c958f6106a80f88"]}},"8151a09c160747c3a779c0f0ee38e417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed450902b9d64b479cc55d2ee940ae68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_85423849dd5b4de9b032b75aee57ab1b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":87319819,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":87319819,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d733899d4104fd799908edbde3aeaf9"}},"aba9df5eae754d889c958f6106a80f88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_432c0dce1ddd437b9f99d9fb32b9ca72","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 83.3M/83.3M [00:13&lt;00:00, 6.71MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d01bba4bd3f04750ba28870f9878036f"}},"85423849dd5b4de9b032b75aee57ab1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3d733899d4104fd799908edbde3aeaf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"432c0dce1ddd437b9f99d9fb32b9ca72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d01bba4bd3f04750ba28870f9878036f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"cells":[{"cell_type":"code","metadata":{"id":"HPDFJYMvaeg9","executionInfo":{"status":"ok","timestamp":1624804174014,"user_tz":-540,"elapsed":4854,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, models\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import cv2\n","\n","from typing import List, Dict, Tuple"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJhQtqoQjzbx","executionInfo":{"status":"ok","timestamp":1624804174015,"user_tz":-540,"elapsed":10,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}},"outputId":"770f1c5b-1a3a-4d51-d4c6-7c28454074f2"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Using {} device'.format(device))"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n"]}]},{"cell_type":"markdown","metadata":{"id":"hO6UGv34jzb0"},"source":["## Pacal VOC 2007 Dataset load"]},{"source":["pre_processing = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])"],"cell_type":"code","metadata":{"id":"OUknsMpKkSoo"},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CuS2k4Fn9az","executionInfo":{"status":"ok","timestamp":1624804181358,"user_tz":-540,"elapsed":6,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["_dataset = datasets.VOCDetection(root='../data/VOC/2007/train', year='2007', image_set='train', download=False, transform=pre_processing)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"hN2hikt3jzb2","executionInfo":{"status":"ok","timestamp":1624804181358,"user_tz":-540,"elapsed":5,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["def imshow(img, norm: bool=False):\n","    if norm:\n","        img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    img = np.transpose(npimg, (1, 2, 0))\n","    return img"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"1V-0N7N3yQ6f","executionInfo":{"status":"ok","timestamp":1624804181646,"user_tz":-540,"elapsed":293,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["classes = {\n","    'person': 0, 'bird': 1,\n","    'cat': 2, 'cow': 3,\n","    'dog': 4, 'horse': 5,\n","    'sheep': 6, 'aeroplane': 7,\n","    'bicycle': 8, 'boat': 9,\n","    'bus': 10, 'car': 11,\n","    'motorbike': 12, 'train': 13,\n","    'bottle': 14, 'chair': 15,\n","    'diningtable': 16, 'pottedplant': 17,\n","    'sofa': 18, 'tvmonitor': 19\n","    }"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZn70yqdpBGz","executionInfo":{"status":"ok","timestamp":1624804181647,"user_tz":-540,"elapsed":17,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["def parse_from_target(classes: Dict, data: Tuple) -> Tuple:\n","    image, target = data\n","    \n","    labels: List = []\n","    bboxes: List = []\n","\n","    for i in range(len(target['annotation']['object'])):\n","        bbox: List = []\n","        _class = target['annotation']['object'][i]['name']\n","        #print(f'class: {_class}')\n","        label = classes[_class]\n","        #print(f'label: {label}')\n","        bndbox = target['annotation']['object'][i]['bndbox']\n","        width = target['annotation']['size']['width']\n","        height = target['annotation']['size']['height']\n","        size = (int(width), int(height))\n","\n","        for key, val in bndbox.items():\n","            bbox.append(int(val))\n","        labels.append(label)\n","        bboxes.append(bbox)\n","\n","    image = torch.tensor(image)\n","    labels = torch.tensor(labels)\n","    bboxes = torch.tensor(bboxes)\n","    size = torch.tensor(size)\n","    #print(f' labels: {labels}')\n","    return image, labels, bboxes, size"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWCIrq_26DG5","executionInfo":{"status":"ok","timestamp":1624804181647,"user_tz":-540,"elapsed":16,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["import torchvision.transforms.functional as FT\n","\n","def resize(image, bboxes, image_size, dims: Tuple=(300, 300), return_percent_coords=True):\n","    width, height = image_size[0], image_size[1]\n","\n","    # Resize image\n","    re_image = FT.resize(image, dims)\n","\n","    # Resize bounding boxes\n","    old_dims = torch.FloatTensor([width, height, width, height]).unsqueeze(0)\n","    re_bboxes: List = []\n","    for bbox in bboxes:\n","        bbox = torch.tensor(bbox)\n","        re_bbox = bbox / old_dims  # percent coordinates\n","        re_bbox = re_bbox.tolist()[0]\n","\n","        for i, rate in enumerate(re_bbox):\n","            if i % 2 == 0:\n","                re_bbox[i] = rate * dims[0]\n","            elif i % 2 == 1:\n","                re_bbox[i] = rate * dims[1]\n","        re_bboxes.append(re_bbox)\n","    re_bboxes = torch.tensor(re_bboxes)\n","\n","    if not return_percent_coords:\n","        new_dims = torch.FloatTensor([dims[1], dims[0], dims[1], dims[0]]).unsqueeze(0)\n","        re_bboxes: List = []\n","        for bbox in bboxes:\n","            bbox = torch.tensor(bbox)\n","            re_bbox = bbox * new_dims\n","            re_bboxes.append(re_bbox.tolist()[0])\n","        re_bboxes = torch.tensor(re_bboxes)\n","\n","    return re_image, re_bboxes"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcvuvKXvjzb7","executionInfo":{"status":"ok","timestamp":1624804181648,"user_tz":-540,"elapsed":15,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["class myDataset(Dataset):\n","    def __init__(self, classes, _dataset, dims: Tuple, norm: bool=False):\n","        super(myDataset, self).__init__()\n","        self.classes = classes\n","        self._dataset = _dataset\n","        self.dims = dims\n","        self.norm = norm\n","\n","    def __len__(self) -> int:\n","        return len(self._dataset)\n","\n","    def __getitem__(self, idx: int):\n","        image, labels, bboxes, image_size = parse_from_target(self.classes, _dataset[idx])\n","        re_image, re_bboxes = resize(image, bboxes, image_size, dims=self.dims)\n","        if self.norm:\n","            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","            re_image = normalize(re_image)\n","\n","        return re_image, labels, re_bboxes\n","\n","    def collate_fn(self, batch):\n","            \"\"\"\n","            Since each image may have a different number of objects, we need a collate function (to be passed to the DataLoader).\n","            This describes how to combine these tensors of different sizes. We use lists.\n","            Note: this need not be defined in this Class, can be standalone.\n","            :param batch: an iterable of N sets from __getitem__()\n","            :return: a tensor of images, lists of varying-size tensors of bounding boxes, labels, and difficulties\n","            \"\"\"\n","\n","            images: List=list()\n","            labels: List=list()\n","            bboxes: List=list()\n","\n","            for b in batch:\n","                images.append(b[0])\n","                labels.append(b[1])\n","                bboxes.append(b[2])\n","            images = torch.stack(images, dim=0)\n","            return images, labels, bboxes\n"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"8B9h-na3jzb9","executionInfo":{"status":"ok","timestamp":1624804181649,"user_tz":-540,"elapsed":13,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["train_ds = myDataset(classes, _dataset, (300, 300))"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9I0PYXTjzb-","executionInfo":{"status":"ok","timestamp":1624804181650,"user_tz":-540,"elapsed":13,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["batch_size=64\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=train_ds.collate_fn)"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBmxP_iqjzb_"},"source":["## Model 정의"]},{"cell_type":"code","metadata":{"id":"uZvkenhgjzcA","executionInfo":{"status":"ok","timestamp":1624804181650,"user_tz":-540,"elapsed":11,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["class BB_model(nn.Module):\n","    def __init__(self):\n","        super(BB_model, self).__init__()\n","        resnet = models.resnet34(pretrained=True)\n","        layers = list(resnet.children())[:8]\n","        self.features1 = nn.Sequential(*layers[:6])\n","        self.features2 = nn.Sequential(*layers[6:])\n","        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n","        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n","        \n","    def forward(self, x):\n","        x = self.features1(x)\n","        x = self.features2(x)\n","        x = F.relu(x)\n","        x = nn.AdaptiveAvgPool2d((1,1))(x)\n","        x = x.view(x.shape[0], -1)\n","        return self.classifier(x), self.bb(x)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eba825fa16f94cc6a7049f0c12f28b59","8151a09c160747c3a779c0f0ee38e417","ed450902b9d64b479cc55d2ee940ae68","aba9df5eae754d889c958f6106a80f88","85423849dd5b4de9b032b75aee57ab1b","3d733899d4104fd799908edbde3aeaf9","432c0dce1ddd437b9f99d9fb32b9ca72","d01bba4bd3f04750ba28870f9878036f"]},"id":"PteH610xjzcD","executionInfo":{"status":"ok","timestamp":1624804194971,"user_tz":-540,"elapsed":13331,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}},"outputId":"30e1e1d1-2f37-4b0e-ab6c-f9da1f872a32"},"source":["model = BB_model().to(device)"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"c31op7pNjzcC","executionInfo":{"status":"ok","timestamp":1624804194972,"user_tz":-540,"elapsed":13,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["def update_optimizer(optimizer, lr):\n","    for i, param_group in enumerate(optimizer.param_groups):\n","        param_group[\"lr\"] = lr"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8lSVL47mMz8","executionInfo":{"status":"ok","timestamp":1624804194973,"user_tz":-540,"elapsed":12,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["learning_rate = 0.001\n","\n","criterion = nn.CrossEntropyLoss()  # 손실함수 설정\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # 최적화 설정"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EErFFQOjzcF","executionInfo":{"status":"ok","timestamp":1624804194974,"user_tz":-540,"elapsed":12,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["def get_accuracy(y, label):\n","    y_idx = torch.argmax(y, dim=1)\n","    result = y_idx - label\n","\n","    num_correct = 0\n","    for i in range(len(result)):\n","        if result[i] == 0:\n","            num_correct += 1\n","\n","    return num_correct/y.shape[0]"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOOZKBxOjzcF","executionInfo":{"status":"ok","timestamp":1624804247847,"user_tz":-540,"elapsed":313,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":["import time\n","\n","def train(dataloader, model, loss_fn, optimizer):\n","    num_batches = len(dataloader)\n","    train_loss_list, train_acc_list = [], []\n","\n","    start_time = time.time()\n","    for batch, (images, labels, bboxes) in enumerate(dataloader):\n","        print(f'image: {len(images)}')\n","        print(f'labels: {len(labels)}')\n","        print(f'bboxes: {len(bboxes)}')\n","        model.train()\n","        # x: 입력, y: 정답(레이블)을 받아온 후 device에 올려줌\n","        images = images.to(device)\n","        labels = [l.to(device) for l in labels]\n","        bboxs = [b.to(device) for b in bboxes]\n","        \n","        # 예측 오류 계산\n","        pred = model(images)\n","        loss = loss_fn(pred, labels)  # 손실함수 계산\n","\n","        # 역전파\n","        optimizer.zero_grad() # 학습 수행 전 미분값을 0으로 초기화(학습전 반드시 처리 필요)\n","        loss.backward()       # 가중치와 편향에 대한 기울기 계산\n","        optimizer.step()      # 가중치와 편향 업데이트\n","\n","        # 학습 정확도 및 손실함수 값 기록\n","        train_acc = get_accuracy(pred, labels)  # 정확도 계산\n","\n","        train_loss_list.append(loss.item())\n","        train_acc_list.append(train_acc)\n","\n","        if (batch+1) % num_batches == 0:\n","            print(f'step: {batch+1}/{num_batches} | {time.time() - start_time:.2f} s/step | ', end='')\n","            print(f'train loss: {np.mean(train_loss_list):.4f} | train acc: {np.mean(train_acc_list):.4f} | ', end='')"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dxlvPMK3jzcI","executionInfo":{"status":"error","timestamp":1624804251130,"user_tz":-540,"elapsed":840,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}},"outputId":"70558de0-7499-47b2-eacf-68552f324766"},"source":["num_epochs = 10\n","for epoch in range(num_epochs):\n","    print(f'Epoch: {epoch+1}/{num_epochs}')\n","    train(train_dl, model, criterion, optimizer)\n","print(\"Done!\")   "],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1/10\n","<ipython-input-40-78b9469910dc>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  image = torch.tensor(image)\n","<ipython-input-41-9c7284f99bb0>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  bbox = torch.tensor(bbox)\n","image: 64\n","labels: 64\n","bboxes: 64\n","/Users/churry/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"error","ename":"TypeError","evalue":"cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-42c4ed02be3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1}/{num_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-cbfd7a887b6b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# 예측 오류 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 손실함수 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# 역전파\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple"]}]},{"cell_type":"code","metadata":{"id":"SZTJz9Duk-LL","executionInfo":{"status":"aborted","timestamp":1624804195936,"user_tz":-540,"elapsed":11,"user":{"displayName":"Cheolhee Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGdkZMo7nH4a6tQKwfZxRyhw1kjpybDrVNPh2OqEM=s64","userId":"08773136853892542450"}}},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}